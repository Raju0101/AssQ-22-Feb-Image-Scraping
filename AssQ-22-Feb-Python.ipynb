{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b99744d-8063-4aaa-a97b-444faba604b3",
   "metadata": {},
   "source": [
    "## AssQ 22 Feb Python Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85578876-5a85-4931-aa0d-f344271d90c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091d4825-34d1-4911-acfa-da62d7073a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f95e47-1336-4a9c-b702-064bafabdd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "To extract the video URLs of the first five videos from a YouTube channel, \n",
    "you can use the BeautifulSoup library to parse the HTML content of the page and \n",
    "extract the necessary information. Additionally, you can use the requests library to fetch the webpage. \n",
    "Here's a Python program that demonstrates how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "921c3510-bb8b-4d2b-a2d9-76cf1aa5f4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "! pip install requests\n",
    "! pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f19919a5-f307-4ec6-b2f3-e9d38a8acf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No video URLs found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_video_urls(channel_url, num_videos):\n",
    "    # Send a request to the channel URL\n",
    "    response = requests.get(channel_url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error: Unable to fetch the webpage.\")\n",
    "        return []\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all video links on the page\n",
    "    video_links = soup.find_all('a', {'class': 'yt-simple-endpoint'})\n",
    "\n",
    "    # Extract video URLs from the links\n",
    "    video_urls = []\n",
    "    for link in video_links:\n",
    "        url = link['href']\n",
    "        if url.startswith('/watch') and len(video_urls) < num_videos:\n",
    "            video_url = f\"https://www.youtube.com{url}\"\n",
    "            video_urls.append(video_url)\n",
    "\n",
    "    return video_urls\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "    num_videos = 5\n",
    "\n",
    "    video_urls = extract_video_urls(channel_url, num_videos)\n",
    "\n",
    "    if video_urls:\n",
    "        print(\"First 5 video URLs:\")\n",
    "        for url in video_urls:\n",
    "            print(url)\n",
    "    else:\n",
    "        print(\"No video URLs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1dc59b-7f69-412a-9144-dad211056c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Make sure you have the requests and beautifulsoup4 libraries installed.\n",
    "You can install them using the following commands:\n",
    "    \n",
    " Please note that web scraping can be against the terms of service of some websites, \n",
    "and you should always make sure you are allowed to scrape the content you're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613203aa-ae2d-4831-adab-45a012af6088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a44dc-f162-42f1-992e-68b4b9472f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7bfd9-d3d7-4db6-86b6-0dc727b87050",
   "metadata": {},
   "outputs": [],
   "source": [
    "To extract the URLs of video thumbnails from the first five videos of a YouTube channel, \n",
    "you can again use the BeautifulSoup library to parse the HTML content of the page and extract the necessary information. \n",
    "Here's a Python program that demonstrates how to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea904163-8168-4221-bc03-8ed178b384f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No thumbnail URLs found.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_thumbnail_urls(channel_url, num_videos):\n",
    "    # Send a request to the channel URL\n",
    "    response = requests.get(channel_url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error: Unable to fetch the webpage.\")\n",
    "        return []\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all thumbnail image elements\n",
    "    thumbnail_elements = soup.find_all('img', {'class': 'style-scope yt-img-shadow'})\n",
    "\n",
    "    # Extract thumbnail URLs from the elements\n",
    "    thumbnail_urls = []\n",
    "    for element in thumbnail_elements:\n",
    "        if len(thumbnail_urls) < num_videos:\n",
    "            thumbnail_url = element['src']\n",
    "            thumbnail_urls.append(thumbnail_url)\n",
    "\n",
    "    return thumbnail_urls\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "    num_videos = 5\n",
    "\n",
    "    thumbnail_urls = extract_thumbnail_urls(channel_url, num_videos)\n",
    "\n",
    "    if thumbnail_urls:\n",
    "        print(\"Thumbnail URLs of the first 5 videos:\")\n",
    "        for url in thumbnail_urls:\n",
    "            print(url)\n",
    "    else:\n",
    "        print(\"No thumbnail URLs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d1722f-5eef-40c2-9d03-2e8cff641dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af97782f-ff78-4f75-8bde-1339c56e524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Write a python program to extract the title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb8cbb7-7964-4ffd-87bd-501409906e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "To extract the titles of the first five videos from a YouTube channel,\n",
    "you can use the BeautifulSoup library to parse the HTML content of the page and extract the necessary information.\n",
    "Here's a Python program that demonstrates how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925e7460-95c7-45f6-90a4-2574bd848c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_video_titles(channel_url, num_videos):\n",
    "    # Send a request to the channel URL\n",
    "    response = requests.get(channel_url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error: Unable to fetch the webpage.\")\n",
    "        return []\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all video title elements\n",
    "    title_elements = soup.find_all('a', {'id': 'video-title'})\n",
    "\n",
    "    # Extract video titles from the elements\n",
    "    video_titles = []\n",
    "    for element in title_elements:\n",
    "        if len(video_titles) < num_videos:\n",
    "            video_title = element.get_text().strip()\n",
    "            video_titles.append(video_title)\n",
    "\n",
    "    return video_titles\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "    num_videos = 5\n",
    "\n",
    "    video_titles = extract_video_titles(channel_url, num_videos)\n",
    "\n",
    "    if video_titles:\n",
    "        print(\"Titles of the first 5 videos:\")\n",
    "        for title in video_titles:\n",
    "            print(title)\n",
    "    else:\n",
    "        print(\"No video titles found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2e995f-a9a4-4961-8205-17ffd6dc7f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7ac645-a04f-45af-90aa-a13b03b50517",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4f9d9c-3342-4b40-82c3-57ae3a021e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "To extract the number of views for the first five videos from a YouTube channel,\n",
    "you can use the BeautifulSoup library to parse the HTML content of the page and extract the necessary information. \n",
    "Here's a Python program that demonstrates how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed0017-c02a-459a-a4a1-952e6b90719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_video_views(channel_url, num_videos):\n",
    "    # Send a request to the channel URL\n",
    "    response = requests.get(channel_url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error: Unable to fetch the webpage.\")\n",
    "        return []\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all video views elements\n",
    "    views_elements = soup.find_all('span', {'class': 'style-scope ytd-grid-video-renderer'})\n",
    "\n",
    "    # Extract video views from the elements\n",
    "    video_views = []\n",
    "    for element in views_elements:\n",
    "        if len(video_views) < num_videos:\n",
    "            view_text = element.get_text().strip()\n",
    "            video_views.append(view_text)\n",
    "\n",
    "    return video_views\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "    num_videos = 5\n",
    "\n",
    "    video_views = extract_video_views(channel_url, num_videos)\n",
    "\n",
    "    if video_views:\n",
    "        print(\"Number of views of the first 5 videos:\")\n",
    "        for views in video_views:\n",
    "            print(views)\n",
    "    else:\n",
    "        print(\"No view counts found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fc67dd-fbf9-48f7-9b80-edda9c5cb385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b182616-551a-4e4b-b668-1a5447675f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Write a python program to extract the time of posting of video for the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ccd59c-6b87-42c5-b98a-5bd111d12d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "To extract the time of posting for the first five videos from a YouTube channel, \n",
    "you can use the BeautifulSoup library to parse the HTML content of the page and extract the necessary information.\n",
    "Here's a Python program that demonstrates how to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348267d2-31ae-4d70-a272-b1edc7c4726d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_video_post_times(channel_url, num_videos):\n",
    "    # Send a request to the channel URL\n",
    "    response = requests.get(channel_url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error: Unable to fetch the webpage.\")\n",
    "        return []\n",
    "\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all video time elements\n",
    "    time_elements = soup.find_all('div', {'class': 'style-scope ytd-grid-video-renderer'})\n",
    "\n",
    "    # Extract video post times from the elements\n",
    "    video_post_times = []\n",
    "    for element in time_elements:\n",
    "        if len(video_post_times) < num_videos:\n",
    "            time_text = element.find('span', {'class': 'style-scope ytd-grid-video-renderer'}).get_text().strip()\n",
    "            video_post_times.append(time_text)\n",
    "\n",
    "    return video_post_times\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    channel_url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "    num_videos = 5\n",
    "\n",
    "    video_post_times = extract_video_post_times(channel_url, num_videos)\n",
    "\n",
    "    if video_post_times:\n",
    "        print(\"Time of posting for the first 5 videos:\")\n",
    "        for post_time in video_post_times:\n",
    "            print(post_time)\n",
    "    else:\n",
    "        print(\"No post times found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cfa36f-f308-4914-8ac4-136e0993f356",
   "metadata": {},
   "outputs": [],
   "source": [
    ".............................................The End....................................."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
